{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for TSLA saved to CSV, Excel, and JSON files.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager  # Automatically manages ChromeDriver\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Function to scrape historical stock data\n",
    "def scrape_stock_data(ticker, start_date, end_date):\n",
    "    # Construct the URL for historical data\n",
    "    url = f\"https://finance.yahoo.com/quote/{ticker}/history?period1={start_date}&period2={end_date}&interval=1d&filter=history&frequency=1d\"\n",
    "    \n",
    "    # Set up Selenium WebDriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run in headless mode (no browser UI)\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for the page to load\n",
    "    time.sleep(10)  # Increase sleep time to ensure the page loads completely\n",
    "    \n",
    "    # Parse the page source with BeautifulSoup\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "    \n",
    "    # Extract the historical data table\n",
    "    table = soup.find(\"table\")\n",
    "    if table is None:\n",
    "        raise ValueError(\"Table not found. The page structure may have changed.\")\n",
    "    \n",
    "    rows = table.find_all(\"tr\")[1:-1]  # Skip header and dividend rows\n",
    "    \n",
    "    # Extract data into a list of dictionaries\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) == 7:  # Ensure the row contains valid data\n",
    "            data.append({\n",
    "                \"Date\": cols[0].text.strip(),\n",
    "                \"Open\": cols[1].text.strip(),\n",
    "                \"High\": cols[2].text.strip(),\n",
    "                \"Low\": cols[3].text.strip(),\n",
    "                \"Close\": cols[4].text.strip(),\n",
    "                \"Adj Close\": cols[5].text.strip(),\n",
    "                \"Volume\": cols[6].text.strip()\n",
    "            })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Define the stock ticker and time period\n",
    "ticker = \"TSLA\"\n",
    "start_date = 1630454400  # Unix timestamp for September 1, 2021\n",
    "end_date = 1661990400    # Unix timestamp for September 1, 2022\n",
    "\n",
    "# Scrape the data\n",
    "try:\n",
    "    stock_data = scrape_stock_data(ticker, start_date, end_date)\n",
    "    \n",
    "    # Convert to a pandas DataFrame\n",
    "    df = pd.DataFrame(stock_data)\n",
    "    \n",
    "    # Save the data to CSV, Excel, and JSON\n",
    "    df.to_csv(f\"{ticker}_historical_data.csv\", index=False)\n",
    "    df.to_excel(f\"{ticker}_historical_data.xlsx\", index=False)\n",
    "    df.to_json(f\"{ticker}_historical_data.json\", orient=\"records\", indent=4)\n",
    "    \n",
    "    print(f\"Data for {ticker} saved to CSV, Excel, and JSON files.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for TSLA scraped successfully.\n",
      "Data for AAPL scraped successfully.\n",
      "Data for MSFT scraped successfully.\n",
      "Data for GOOGL scraped successfully.\n",
      "Data for AMZN scraped successfully.\n",
      "Data for FB scraped successfully.\n",
      "Combined data saved to CSV, Excel, and JSON files.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Function to scrape historical stock data\n",
    "def scrape_stock_data(ticker, start_date, end_date):\n",
    "    # Construct the URL for historical data\n",
    "    url = f\"https://finance.yahoo.com/quote/{ticker}/history?period1={start_date}&period2={end_date}&interval=1d&filter=history&frequency=1d\"\n",
    "    \n",
    "    # Set up Selenium WebDriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run in headless mode (no browser UI)\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for the page to load\n",
    "    time.sleep(10)  # Increase sleep time to ensure the page loads completely\n",
    "    \n",
    "    # Parse the page source with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "    \n",
    "    # Extract the historical data table\n",
    "    table = soup.find(\"table\")\n",
    "    if table is None:\n",
    "        raise ValueError(f\"Table not found for ticker {ticker}. The page structure may have changed.\")\n",
    "    \n",
    "    rows = table.find_all(\"tr\")[1:-1]  # Skip header and dividend rows\n",
    "    \n",
    "    # Extract data into a list of dictionaries\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) == 7:  # Ensure the row contains valid data\n",
    "            data.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Date\": cols[0].text.strip(),\n",
    "                \"Open\": cols[1].text.strip(),\n",
    "                \"High\": cols[2].text.strip(),\n",
    "                \"Low\": cols[3].text.strip(),\n",
    "                \"Close\": cols[4].text.strip(),\n",
    "                \"Adj Close\": cols[5].text.strip(),\n",
    "                \"Volume\": cols[6].text.strip()\n",
    "            })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Define the list of stock tickers and time period\n",
    "tickers = [\"TSLA\", \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"FB\"]\n",
    "start_date = 1630454400  # Unix timestamp for September 1, 2021\n",
    "end_date = 1661990400    # Unix timestamp for September 1, 2022\n",
    "\n",
    "# Initialize an empty list to hold all data\n",
    "all_data = []\n",
    "\n",
    "# Scrape data for each ticker\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        stock_data = scrape_stock_data(ticker, start_date, end_date)\n",
    "        all_data.extend(stock_data)\n",
    "        print(f\"Data for {ticker} scraped successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while scraping {ticker}: {e}\")\n",
    "\n",
    "# Convert the combined data to a pandas DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Save the combined data to CSV, Excel, and JSON\n",
    "df.to_csv(\"combined_historical_data.csv\", index=False)\n",
    "df.to_excel(\"combined_historical_data.xlsx\", index=False)\n",
    "df.to_json(\"combined_historical_data.json\", orient=\"records\", indent=4)\n",
    "\n",
    "print(\"Combined data saved to CSV, Excel, and JSON files.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
